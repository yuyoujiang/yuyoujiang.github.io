"use strict";(self.webpackChunkyoujiang_site=self.webpackChunkyoujiang_site||[]).push([[185],{2771:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>a,frontMatter:()=>r,metadata:()=>l,toc:()=>d});var t=s(4848),i=s(8453);const r={title:"Exercise Counter",slug:"/exercise-counter",sidebar_position:2},o="Exercise Counter with YOLOv8 on NVIDIA Jetson",l={id:"exercise-counter-on-jetson",title:"Exercise Counter",description:"ezgif com-optimize (1)",source:"@site/docs/exercise-counter-on-jetson.md",sourceDirName:".",slug:"/exercise-counter",permalink:"/docs/exercise-counter",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/exercise-counter-on-jetson.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{title:"Exercise Counter",slug:"/exercise-counter",sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Local Voice Chatbot",permalink:"/docs/local-voice-chatbot"},next:{title:"Image Fusion with Yolo",permalink:"/docs/image-fusion"}},c={},d=[{value:"Introduction",id:"introduction",level:2},{value:"Installation",id:"installation",level:2},{value:"Prepare The Model File",id:"prepare-the-model-file",level:2},{value:"Let&#39;s Run It!",id:"lets-run-it",level:2},{value:"For video",id:"for-video",level:3},{value:"For webcam",id:"for-webcam",level:3},{value:"References",id:"references",level:2}];function h(e){const n={a:"a",br:"br",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h1,{id:"exercise-counter-with-yolov8-on-nvidia-jetson",children:"Exercise Counter with YOLOv8 on NVIDIA Jetson"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{src:"https://github.com/yuyoujiang/exercise-counting-with-YOLOv8/assets/76863444/d592ff9b-6bc2-4017-8731-cf408052f0dd",alt:"ezgif com-optimize (1)"})}),"\n",(0,t.jsxs)(n.p,{children:["This is a pose estimation demo application for exercise counting with YOLOv8 using ",(0,t.jsx)(n.a,{href:"https://docs.ultralytics.com/tasks/pose",children:"YOLOv8-Pose"})," model.\r\nClick here to see more ",(0,t.jsx)(n.a,{href:"https://www.seeedstudio.com/edge-ai/computer-vision",children:"vision AI demo and project"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:["This has been tested and deployed on a ",(0,t.jsx)(n.a,{href:"https://www.seeedstudio.com/reComputer-J4011-p-5585.html?queryID=7e0c2522ee08fd79748dfc07645fdd96&objectID=5585&indexName=bazaar_retailer_products",children:"reComputer Jetson J4011"}),". However, you can use any NVIDIA Jetson device to deploy this demo."]}),"\n",(0,t.jsx)(n.p,{children:"Current only 3 different exercise types can be counted:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Squats"}),"\n",(0,t.jsx)(n.li,{children:"Pushups"}),"\n",(0,t.jsx)(n.li,{children:"Situps"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"However, I will keep updating this repo to add more exercises and also add the function of detecting the exercise type."}),"\n",(0,t.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,t.jsxs)(n.p,{children:["The YOLOv8-Pose model can detect 17 key points in the human body, then select discriminative key-points based on the characteristics of the exercise.\r\nCalculate the angle between key-point lines, when the angle reaches a certain threshold, the target can be considered to have completed a certain action.\r\nBy utilizing the above-mentioned mechanism, it is possible to achieve an interesting ",(0,t.jsx)(n.em,{children:"Exercise Counter"})," Application."]}),"\n",(0,t.jsx)(n.h2,{id:"installation",children:"Installation"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Step 1:"})," Flash JetPack OS to reComputer Jetson device ",(0,t.jsx)(n.a,{href:"https://wiki.seeedstudio.com/reComputer_J4012_Flash_Jetpack/",children:"(Refer to here)"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Step 2:"})," Access the terminal of Jetson device, install pip and upgrade it"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sh",children:"sudo apt update\r\nsudo apt install -y python3-pip\r\npip3 install --upgrade pip\n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Step 3:"})," Clone the following repo"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sh",children:"git clone https://github.com/ultralytics/ultralytics.git\n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Step 4:"})," Open requirements.txt"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sh",children:"cd ultralytics\r\nvi requirements.txt\n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Step 5:"})," Edit the following lines. Here you need to press i first to enter editing mode. Press ESC, then type ",":wq"," to save and quit"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sh",children:"# torch>=1.7.0\r\n# torchvision>=0.8.1\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Note:"})," torch and torchvision are excluded for now because they will be installed later."]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Step 6:"})," Install the necessary packages"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sh",children:"pip3 install -e .\n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Step 7:"})," If there is an error in numpy version, install the required version of numpy"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sh",children:"pip3 install numpy==1.20.3\n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Step 8:"})," Install PyTorch and Torchvision ",(0,t.jsx)(n.a,{href:"https://wiki.seeedstudio.com/YOLOv8-DeepStream-TRT-Jetson/#install-pytorch-and-torchvision",children:"(Refer to here)"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Step 9:"})," Run the following command to make sure yolo is installed properly"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sh",children:"yolo detect predict model=yolov8n.pt source='https://ultralytics.com/images/bus.jpg' \n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Step 10:"})," Clone exercise counter demo"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sh",children:"git clone https://github.com/yuyoujiang/exercise-counting-with-YOLOv8.git\n"})}),"\n",(0,t.jsx)(n.h2,{id:"prepare-the-model-file",children:"Prepare The Model File"}),"\n",(0,t.jsx)(n.p,{children:"YOLOv8-pose pretrained pose models are PyTorch models and you can directly use them for inferencing on the Jetson device. However, to have a better speed, you can convert the PyTorch models to TensorRT optimized models by following below instructions."}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Step 1:"})," Download model weights in PyTorch format ",(0,t.jsx)(n.a,{href:"https://docs.ultralytics.com/tasks/pose/#models",children:"(Refer to here)"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Step 2:"})," Execute the following command to convert this PyTorch model into a TensorRT model"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sh",children:"# TensorRT FP32 export\r\nyolo export model=yolov8s-pose.pt format=engine device=0\r\n\r\n# TensorRT FP16 export\r\nyolo export model=yolov8s-pose.pt format=engine half=True device=0\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Tip:"})," ",(0,t.jsx)(n.a,{href:"https://docs.ultralytics.com/modes/export",children:"Click here"})," to learn more about yolo export"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Step 3:"})," Prepare a video to be tested."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"lets-run-it",children:"Let's Run It!"}),"\n",(0,t.jsxs)(n.p,{children:["To run the exercise counter, enter the following commands with the ",(0,t.jsx)(n.code,{children:"exercise_type"})," as:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"sit-up"}),"\n",(0,t.jsx)(n.li,{children:"pushup"}),"\n",(0,t.jsx)(n.li,{children:"squat"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"for-video",children:"For video"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sh",children:"python3 demo.py --sport <exercise_type> --model yolov8s-pose.pt --show True --input <path_to_your_video>\n"})}),"\n",(0,t.jsx)(n.h3,{id:"for-webcam",children:"For webcam"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-sh",children:"python3 demo.py --sport <exercise_type> --model yolov8s-pose.pt --show True --input 0\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{src:"https://github.com/yuyoujiang/exercise-counting-with-YOLOv8/assets/76863444/414e1cd1-ab7d-4ca6-91e4-c8a948fe55ae",alt:"result 00_00_00-00_00_30"})}),"\n",(0,t.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://github.com/ultralytics/",children:"https://github.com/ultralytics/"}),(0,t.jsx)(n.br,{}),"\n",(0,t.jsx)(n.a,{href:"https://wiki.seeedstudio.com/YOLOv8-DeepStream-TRT-Jetson/",children:"https://wiki.seeedstudio.com"})]})]})}function a(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(h,{...e})}):h(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>o,x:()=>l});var t=s(6540);const i={},r=t.createContext(i);function o(e){const n=t.useContext(r);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);