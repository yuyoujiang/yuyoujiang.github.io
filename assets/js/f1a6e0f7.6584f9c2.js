"use strict";(self.webpackChunkyoujiang_site=self.webpackChunkyoujiang_site||[]).push([[467],{7492:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>d,frontMatter:()=>a,metadata:()=>s,toc:()=>_});var i=r(4848),t=r(8453);const a={title:"Local Voice Chatbot",slug:"/local-voice-chatbot",sidebar_position:1},o="Deploy Riva and Llama2 on Jetson",s={id:"local-voice-chatbot-on-jetson",title:"Local Voice Chatbot",description:"Introduction",source:"@site/docs/local-voice-chatbot-on-jetson.md",sourceDirName:".",slug:"/local-voice-chatbot",permalink:"/docs/local-voice-chatbot",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/local-voice-chatbot-on-jetson.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{title:"Local Voice Chatbot",slug:"/local-voice-chatbot",sidebar_position:1},sidebar:"tutorialSidebar",next:{title:"Exercise Counter",permalink:"/docs/exercise-counter"}},c={},_=[{value:"Introduction",id:"introduction",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Getting Started",id:"getting-started",level:2},{value:"Hardware Connection",id:"hardware-connection",level:3},{value:"Install Riva Server",id:"install-riva-server",level:3},{value:"Install and run LLM",id:"install-and-run-llm",level:3},{value:"Clone local chatbot demo and try to run it.",id:"clone-local-chatbot-demo-and-try-to-run-it",level:3},{value:"Effect Demonstration",id:"effect-demonstration",level:2},{value:"References",id:"references",level:2}];function l(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components},{Details:r}=n;return r||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"deploy-riva-and-llama2-on-jetson",children:"Deploy Riva and Llama2 on Jetson"}),"\n",(0,i.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,i.jsx)(n.p,{children:"As artificial intelligence technology rapidly evolves, voice interaction has become an increasingly important mode of human-computer interaction. Especially in fields like smart homes, personal assistants, and customer service support, the demand for voice chatbots is growing significantly. However, most existing voice chatbots rely on cloud computing services, which raises concerns about data privacy and network latency to some extent."}),"\n",(0,i.jsx)("div",{align:"center",children:(0,i.jsx)("img",{width:800,src:"https://files.seeedstudio.com/wiki/reComputer/Application/Local_Voice_Chatbot/workflow.png"})}),"\n",(0,i.jsxs)(n.p,{children:["This project aims to address these issues by building a locally-operated voice chatbot. Utilizing ",(0,i.jsx)(n.a,{href:"https://docs.nvidia.com/deeplearning/riva/user-guide/docs/quick-start-guide.html",children:"Nvidia Riva"})," and ",(0,i.jsx)(n.a,{href:"https://huggingface.co/meta-llama",children:"Meta Llama2"}),", we have developed a secure, private, and fast-responding voice interaction system."]}),"\n",(0,i.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Jetson device with more than 16GB of memory."}),"\n",(0,i.jsxs)(n.li,{children:["The hardware device needs to be pre-flashed with the jetpack ",(0,i.jsx)(n.a,{href:"https://wiki.seeedstudio.com/reComputer_Intro/",children:"5.1.1"})," operating system."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"https://www.seeedstudio.com/ReSpeaker-USB-Mic-Array-p-4247.html?queryID=dd9c8d91c63781d66776771a7ee5ec01&objectID=4247&indexName=bazaar_retailer_products",children:"Speaker and Microphone"}),"."]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Note:"})," I completed all experiments using ",(0,i.jsx)(n.a,{href:"https://www.seeedstudio.com/AGX-Orin-32GB-H01-Kit-p-5569.html?queryID=012e528073e90bf80afd3880f3fc2b13&objectID=5569&indexName=bazaar_retailer_products",children:"Jetson AGX Orin 32GB H01 Kit"}),", but you can try loading smaller models with a device that has less memory."]}),"\n",(0,i.jsx)(n.h2,{id:"getting-started",children:"Getting Started"}),"\n",(0,i.jsx)(n.h3,{id:"hardware-connection",children:"Hardware Connection"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Connect the audio input/output device to the reComputer."}),"\n",(0,i.jsx)(n.li,{children:"Power on the reComputer and ensure it has normal network access."}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"install-riva-server",children:"Install Riva Server"}),"\n",(0,i.jsxs)(n.p,{children:["Please refer ",(0,i.jsx)(n.a,{href:"https://docs.nvidia.com/deeplearning/riva/user-guide/docs/quick-start-guide.html#embedded",children:"here"})," for more detailed information."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Step1."}),"  Access and log into ",(0,i.jsx)(n.a,{href:"https://catalog.ngc.nvidia.com/?filters=&orderBy=weightPopularDESC&query=",children:"NVIDIA NGC"}),"."]}),"\n",(0,i.jsx)("div",{align:"center",children:(0,i.jsx)("img",{width:800,src:"https://files.seeedstudio.com/wiki/reComputer/Application/Local_Voice_Chatbot/setup_riva_1.png"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Step2."})," Obtain the NGC API Key."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.code,{children:"Account(top right corner)"})," --\x3e ",(0,i.jsx)(n.code,{children:"Setup"})," --\x3e ",(0,i.jsx)(n.code,{children:"Get API Key"})," --\x3e ",(0,i.jsx)(n.code,{children:"Generate API Key"})," --\x3e ",(0,i.jsx)(n.code,{children:"Confirm"})]}),"\n",(0,i.jsx)("div",{align:"center",children:(0,i.jsx)("img",{width:800,src:"https://files.seeedstudio.com/wiki/reComputer/Application/Local_Voice_Chatbot/setup_riva_2.png"})}),"\n",(0,i.jsx)(n.admonition,{type:"info",children:(0,i.jsx)(n.p,{children:"Please record the generated API Key."})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Step3."})," Configure NGC on reComputer"]}),"\n",(0,i.jsxs)(n.p,{children:["Open the reComputer terminal (You can quickly open a terminal on the desktop of reComputer using the shortcut keys ",(0,i.jsx)(n.code,{children:"Ctrl+Alt+T"}),", or you can remotely access the terminal of reComputer using another computer.) and enter the following commands one by one."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sh",children:'cd ~ && mkdir ngc_setup && cd ngc_setup\r\nwget --content-disposition https://api.ngc.nvidia.com/v2/resources/nvidia/ngc-apps/ngc_cli/versions/3.36.0/files/ngccli_arm64.zip && unzip ngccli_arm64.zip \r\nchmod u+x ngc-cli/ngc\r\necho "export PATH=\\"\\$PATH:$(pwd)/ngc-cli\\"" >> ~/.bash_profile && source ~/.bash_profile\r\nngc config set\n'})}),"\n",(0,i.jsx)(n.p,{children:"Enter the relevant information in the terminal interactive interface."}),"\n",(0,i.jsx)("div",{align:"center",children:(0,i.jsx)("img",{width:800,src:"https://files.seeedstudio.com/wiki/reComputer/Application/Local_Voice_Chatbot/setup_riva_3.png"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Step4."})," Install and run the Riva server on reComputer."]}),"\n",(0,i.jsx)(n.p,{children:"In the terminal of reComputer, enter the following commands."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sh",children:"cd ~ && mkdir riva_setup && cd riva_setup\r\nngc registry resource download-version nvidia/riva/riva_quickstart_arm64:2.13.1\r\ncd riva_quickstart_v2.13.1\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Use ",(0,i.jsx)(n.code,{children:"Vim"})," to modify the configuration file."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sh",children:"vim config.sh\r\n\r\n# Press the `A` key on the keyboard to enter edit mode.\r\n# Edit lines 18 and 20 following the instructions below.\r\n\r\n# service_enabled_nlp=true --\x3e service_enabled_nlp=false\r\n# service_enabled_nmt=true --\x3e service_enabled_nmt=false\r\n\r\n# Press the `ESC` on the keyboard to exit edit mode, then use the shortcut `Shift+Z Z` to save the edited content and close the editor.\n"})}),"\n",(0,i.jsx)(n.p,{children:"The configuration file after editing\uff1a"}),"\n",(0,i.jsxs)(r,{children:[(0,i.jsx)("summary",{children:" config.sh "}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sh",children:'# Copyright (c) 2022, NVIDIA CORPORATION.  All rights reserved.\r\n#\r\n# NVIDIA CORPORATION and its licensors retain all intellectual property\r\n# and proprietary rights in and to this software, related documentation\r\n# and any modifications thereto.  Any use, reproduction, disclosure or\r\n# distribution of this software and related documentation without an express\r\n# license agreement from NVIDIA CORPORATION is strictly prohibited.\r\n\r\n# GPU family of target platform. Supported values: tegra, non-tegra\r\nriva_target_gpu_family="non-tegra"\r\n\r\n# Name of tegra platform that is being used. Supported tegra platforms: orin, xavier\r\nriva_tegra_platform="orin"\r\n\r\n# Enable or Disable Riva Services\r\n# For any language other than en-US: service_enabled_nlp must be set to false\r\nservice_enabled_asr=true\r\nservice_enabled_nlp=false\r\nservice_enabled_tts=true\r\nservice_enabled_nmt=false\r\n\r\n# Configure translation services\r\n# Text-to-Text translation (T2T):\r\n# - service_enabled_nmt must be set to true\r\n# - Uncomment desired model for source and target languages in models_nmt field\r\n# Speech-to-Text translation (S2T):\r\n# - service_enabled_asr, service_enabled_nmt must be set to true\r\n# - Set language code of input speech in the asr_language_code field\r\n# - Uncomment desired model for source and target languages in models_nmt field\r\n# Speech-to-Speech translation (S2S):\r\n# - service_enabled_asr, service_enabled_nmt, service_enabled_tts must be set to true\r\n# - Set language code of input speech in the asr_language_code field\r\n# - Uncomment desired model for source and target languages in models_nmt field\r\n# - Set language code of output speech in the tts_language_code field\r\n\r\n# Enable Riva Enterprise\r\n# If enrolled in Enterprise, enable Riva Enterprise by setting configuration\r\n# here. You must explicitly acknowledge you have read and agree to the EULA.\r\n# RIVA_API_KEY=<ngc api key>\r\n# RIVA_API_NGC_ORG=<ngc organization>\r\n# RIVA_EULA=accept\r\n\r\n# Language code to fetch ASR models of a specific language\r\n# Supported language codes: ar-AR, en-US, en-GB, de-DE, es-ES, es-US, fr-FR, hi-IN, it-IT, ja-JP, ru-RU, ko-KR, pt-BR, zh-CN, es-en-US, ja-en-JP\r\n# For multiple languages enter space separated language codes.\r\nasr_language_code=("en-US")\r\n\r\n# ASR acoustic model architecture\r\n# Supported values are: conformer, conformer_xl (en-US + amd64 only), citrinet_1024, citrinet_256 (en-US + arm64 only), jasper (en-US + amd64 only), quartznet (en-US + amd64 only)\r\nasr_acoustic_model=("conformer")\r\n\r\n# ASR acoustic model architecture variant\r\n# Supported values for the architecture are:\r\n# conformer: unified(de-DE, ja-JP and zh-CN only), ml_cs(es-en-US only), unified_ml_cs(ja-en-JP only)\r\n# For the default model, keep the field empty\r\nasr_acoustic_model_variant=("")\r\n\r\n# ASR decoder type to be used\r\n# If you\'d like to use greedy decoder for ASR instead of flashlight/os2s decoder then set the below $use_asr_greedy_decoder to true\r\nuse_asr_greedy_decoder=false\r\n\r\n# Language code to fetch TTS models of a specific language\r\n# Supported language codes: en-US, es-ES, it-IT, de-DE, zh-CN\r\n# For multiple languages enter space separated language codes\r\ntts_language_code=("en-US")\r\n\r\n# Specify one or more GPUs to use\r\n# specifying more than one GPU is currently an experimental feature, and may result in undefined behaviours.\r\ngpus_to_use="device=0"\r\n\r\n# Specify the encryption key to use to deploy models\r\nMODEL_DEPLOY_KEY="tlt_encode"\r\n\r\n# Locations to use for storing models artifacts\r\n#\r\n# If an absolute path is specified, the data will be written to that location\r\n# Otherwise, a Docker volume will be used (default).\r\n#\r\n# riva_init.sh will create a `rmir` and `models` directory in the volume or\r\n# path specified.\r\n#\r\n# RMIR ($riva_model_loc/rmir)\r\n# Riva uses an intermediate representation (RMIR) for models\r\n# that are ready to deploy but not yet fully optimized for deployment. Pretrained\r\n# versions can be obtained from NGC (by specifying NGC models below) and will be\r\n# downloaded to $riva_model_loc/rmir by `riva_init.sh`\r\n#\r\n# Custom models produced by NeMo or TLT and prepared using riva-build\r\n# may also be copied manually to this location $(riva_model_loc/rmir).\r\n#\r\n# Models ($riva_model_loc/models)\r\n# During the riva_init process, the RMIR files in $riva_model_loc/rmir\r\n# are inspected and optimized for deployment. The optimized versions are\r\n# stored in $riva_model_loc/models. The riva server exclusively uses these\r\n# optimized versions.\r\nriva_model_loc="riva-model-repo"\r\n\r\nif [[ $riva_target_gpu_family == "tegra" ]]; then\r\n    riva_model_loc="`pwd`/model_repository"\r\nfi\r\n\r\n# The default RMIRs are downloaded from NGC by default in the above $riva_rmir_loc directory\r\n# If you\'d like to skip the download from NGC and use the existing RMIRs in the $riva_rmir_loc\r\n# then set the below $use_existing_rmirs flag to true. You can also deploy your set of custom\r\n# RMIRs by keeping them in the riva_rmir_loc dir and use this quickstart script with the\r\n# below flag to deploy them all together.\r\nuse_existing_rmirs=false\r\n\r\n# Ports to expose for Riva services\r\nriva_speech_api_port="50051"\r\n\r\n# NGC orgs\r\nriva_ngc_org="nvidia"\r\nriva_ngc_team="riva"\r\nriva_ngc_image_version="2.13.1"\r\nriva_ngc_model_version="2.13.0"\r\n\r\n# Pre-built models listed below will be downloaded from NGC. If models already exist in $riva-rmir\r\n# then models can be commented out to skip download from NGC\r\n\r\n########## ASR MODELS ##########\r\n\r\nmodels_asr=()\r\n\r\nfor lang_code in ${asr_language_code[@]}; do\r\n    modified_lang_code="${lang_code//-/_}"\r\n    modified_lang_code=${modified_lang_code,,}\r\n\r\n    decoder=""\r\n    if [ "$use_asr_greedy_decoder" = true ]; then\r\n      decoder="_gre"\r\n    fi\r\n\r\n    if [[ ${asr_acoustic_model_variant} != "" ]]; then\r\n      if [[ ${asr_acoustic_model} == "conformer" && ${asr_acoustic_model_variant} != "unified" && ${asr_acoustic_model_variant} != "ml_cs" && ${asr_acoustic_model_variant} != "unified_ml_cs" ]]; then\r\n        echo "Valid variants for Conformer are: unified, ml_cs and unified_ml_cs."\r\n        exit 1\r\n      elif [[ ${asr_acoustic_model} != "conformer" ]]; then\r\n        echo "Invalid variant for ${asr_acoustic_model}."\r\n        exit 1\r\n      fi\r\n      asr_acoustic_model_variant="_${asr_acoustic_model_variant}"\r\n    fi\r\n\r\n    if [[ ${asr_acoustic_model} == "conformer_xl" && ${lang_code} != "en-US" ]]; then\r\n      echo "Conformer-XL acoustic model is only available for language code en-US."\r\n      exit 1\r\n    fi\r\n\r\n    if [[ ${asr_acoustic_model_variant} == "_unified" && ${lang_code} != "de-DE" && ${lang_code} != "ja-JP" && ${lang_code} != "zh-CN" ]]; then\r\n      echo "Unified Conformer acoustic model is only available for language code de-DE, ja-JP and zh-CN."\r\n      exit 1\r\n    fi\r\n\r\n    if [[ ${asr_acoustic_model_variant} == "_ml_cs" && ${lang_code} != "es-en-US" ]]; then\r\n      echo "Multilingual Code Switch Conformer acoustic model is only available for language code es-en-US."\r\n      exit 1\r\n    fi\r\n\r\n    if [[ ${asr_acoustic_model_variant} == "_unified_ml_cs" && ${lang_code} != "ja-en-JP" ]]; then\r\n      echo "Unified Multilingual Code Switch Conformer acoustic model is only available for language code ja-en-JP."\r\n      exit 1\r\n    fi\r\n\r\n    if [[ $riva_target_gpu_family  == "tegra" ]]; then\r\n\r\n      if [[ ${asr_acoustic_model} == "jasper" || \\\r\n            ${asr_acoustic_model} == "quartznet" || \\\r\n            ${asr_acoustic_model} == "conformer_xl" ]]; then\r\n          echo "Conformer-XL, Jasper and Quartznet models are not available for arm64 architecture"\r\n          exit 1\r\n      fi\r\n\r\n      if [[ ${asr_acoustic_model} == "citrinet_256" && ${lang_code} != "en-US" ]]; then\r\n        echo "For arm64 architecture, citrinet_256 acoustic model is only available for language code en-US."\r\n        exit 1\r\n      fi\r\n\r\n      models_asr+=(\r\n      ### Streaming w/ CPU decoder, best latency configuration\r\n          "${riva_ngc_org}/${riva_ngc_team}/models_asr_${asr_acoustic_model}${asr_acoustic_model_variant}_${modified_lang_code}_str:${riva_ngc_model_version}-${riva_target_gpu_family}-${riva_tegra_platform}"\r\n\r\n      ### Offline w/ CPU decoder\r\n      #    "${riva_ngc_org}/${riva_ngc_team}/rmir_asr_${asr_acoustic_model}${asr_acoustic_model_variant}_${modified_lang_code}_ofl${decoder}:${riva_ngc_model_version}"\r\n      )\r\n    else\r\n\r\n      if [[ ${asr_acoustic_model} != "conformer" && \\\r\n            ${asr_acoustic_model} != "conformer_xl" && \\\r\n            ${asr_acoustic_model} != "citrinet_1024" && \\\r\n            ${asr_acoustic_model} != "jasper" && \\\r\n            ${asr_acoustic_model} != "quartznet" ]]; then\r\n        echo "For amd64 architecture, valid acoustic models are conformer, conformer_xl, citrinet_1024, jasper and quartznet."\r\n        exit 1\r\n      fi\r\n\r\n      if [[ (${asr_acoustic_model} == "jasper" || \\\r\n            ${asr_acoustic_model} == "quartznet") && \\\r\n            ${lang_code} != "en-US" ]]; then\r\n        echo "jasper and quartznet acoustic models are only available for language code en-US."\r\n        exit 1\r\n      fi\r\n\r\n      models_asr+=(\r\n      ### Streaming w/ CPU decoder, best latency configuration\r\n          "${riva_ngc_org}/${riva_ngc_team}/rmir_asr_${asr_acoustic_model}${asr_acoustic_model_variant}_${modified_lang_code}_str${decoder}:${riva_ngc_model_version}"\r\n\r\n      ### Streaming w/ CPU decoder, best throughput configuration\r\n      #    "${riva_ngc_org}/${riva_ngc_team}/rmir_asr_${asr_acoustic_model}${asr_acoustic_model_variant}_${modified_lang_code}_str_thr${decoder}:${riva_ngc_model_version}"\r\n\r\n      ### Offline w/ CPU decoder\r\n          "${riva_ngc_org}/${riva_ngc_team}/rmir_asr_${asr_acoustic_model}${asr_acoustic_model_variant}_${modified_lang_code}_ofl${decoder}:${riva_ngc_model_version}"\r\n      )\r\n    fi\r\n\r\n    ### Punctuation model\r\n    if [[ ${asr_acoustic_model_variant} != "_unified" && ${asr_acoustic_model_variant} != "_unified_ml_cs" ]]; then\r\n      pnc_lang=$(echo $modified_lang_code | cut -d "_" -f 1)\r\n      pnc_region=${modified_lang_code##*_}\r\n      modified_lang_code=${pnc_lang}_${pnc_region}\r\n      if [[ $riva_target_gpu_family == "tegra" ]]; then\r\n        models_asr+=(\r\n            "${riva_ngc_org}/${riva_ngc_team}/models_nlp_punctuation_bert_base_${modified_lang_code}:${riva_ngc_model_version}-${riva_target_gpu_family}-${riva_tegra_platform}"\r\n        )\r\n      else\r\n        models_asr+=(\r\n            "${riva_ngc_org}/${riva_ngc_team}/rmir_nlp_punctuation_bert_base_${modified_lang_code}:${riva_ngc_model_version}"\r\n        )\r\n      fi\r\n    fi\r\ndone\r\n\r\n### Speaker diarization model\r\nmodels_asr+=(\r\n#    "${riva_ngc_org}/${riva_ngc_team}/rmir_diarizer_offline:${riva_ngc_model_version}"\r\n)\r\n\r\n########## NLP MODELS ##########\r\n\r\nif [[ $riva_target_gpu_family == "tegra" ]]; then\r\n  models_nlp=(\r\n  ### Bert base Punctuation model\r\n      "${riva_ngc_org}/${riva_ngc_team}/models_nlp_punctuation_bert_base_en_us:${riva_ngc_model_version}-${riva_target_gpu_family}-${riva_tegra_platform}"\r\n\r\n  ### BERT Base Intent Slot model for misty domain fine-tuned on weather, smalltalk/personality, poi/map datasets.\r\n  #    "${riva_ngc_org}/${riva_ngc_team}/models_nlp_intent_slot_misty_bert_base:${riva_ngc_model_version}-${riva_target_gpu_family}-${riva_tegra_platform}"\r\n\r\n  ### DistilBERT Intent Slot model for misty domain fine-tuned on weather, smalltalk/personality, poi/map datasets.\r\n  #    "${riva_ngc_org}/${riva_ngc_team}/models_nlp_intent_slot_misty_distilbert:${riva_ngc_model_version}-${riva_target_gpu_family}-${riva_tegra_platform}"\r\n  )\r\nelse\r\n  models_nlp=(\r\n  ### Bert base Punctuation model\r\n      "${riva_ngc_org}/${riva_ngc_team}/rmir_nlp_punctuation_bert_base_en_us:${riva_ngc_model_version}"\r\n\r\n  ### BERT base Named Entity Recognition model fine-tuned on GMB dataset with class labels LOC, PER, ORG etc.\r\n  #    "${riva_ngc_org}/${riva_ngc_team}/rmir_nlp_named_entity_recognition_bert_base:${riva_ngc_model_version}"\r\n\r\n  ### BERT Base Intent Slot model fine-tuned on weather dataset.\r\n  #    "${riva_ngc_org}/${riva_ngc_team}/rmir_nlp_intent_slot_bert_base:${riva_ngc_model_version}"\r\n\r\n  ### BERT Base Question Answering model fine-tuned on Squad v2.\r\n  #    "${riva_ngc_org}/${riva_ngc_team}/rmir_nlp_question_answering_bert_base:${riva_ngc_model_version}"\r\n\r\n  ### Megatron345M Question Answering model fine-tuned on Squad v2.\r\n  #    "${riva_ngc_org}/${riva_ngc_team}/rmir_nlp_question_answering_megatron:${riva_ngc_model_version}"\r\n\r\n  ### Bert base Text Classification model fine-tuned on 4class (weather, meteorology, personality, nomatch) domain model.\r\n  #    "${riva_ngc_org}/${riva_ngc_team}/rmir_nlp_text_classification_bert_base:${riva_ngc_model_version}"\r\n  )\r\nfi\r\n\r\n########## TTS MODELS ##########\r\n\r\nmodels_tts=()\r\n\r\nfor lang_code in ${tts_language_code[@]}; do\r\n  modified_lang_code="${lang_code//-/_}"\r\n  modified_lang_code=${modified_lang_code,,}\r\n\r\n  if [[ $riva_target_gpu_family == "tegra" ]]; then\r\n    if [[ ${lang_code} == "en-US" ]]; then\r\n      models_tts+=(\r\n      ### These models have been trained with energy conditioning and use the International Phonetic Alphabet (IPA) for inference and training.\r\n          "${riva_ngc_org}/${riva_ngc_team}/models_tts_fastpitch_hifigan_en_us_ipa:${riva_ngc_model_version}-${riva_target_gpu_family}-${riva_tegra_platform}"\r\n      #    "${riva_ngc_org}/${riva_ngc_team}/models_tts_radtts_hifigan_en_us_ipa:${riva_ngc_model_version}-${riva_target_gpu_family}-${riva_tegra_platform}"\r\n\r\n      ### This model uses the ARPABET for inference and training.\r\n      #    "${riva_ngc_org}/${riva_ngc_team}/models_tts_fastpitch_hifigan_en_us:${riva_ngc_model_version}-${riva_target_gpu_family}-${riva_tegra_platform}"\r\n      )\r\n    elif [[ ${lang_code} == "zh-CN" ]]; then\r\n      models_tts+=(\r\n      ### This model is multi-speaker with emotion and and use the International Phonetic Alphabet (IPA) for inference and training.\r\n          "${riva_ngc_org}/${riva_ngc_team}/models_tts_fastpitch_hifigan_zh_cn_ipa:${riva_ngc_model_version}-${riva_target_gpu_family}-${riva_tegra_platform}"\r\n      )\r\n    else\r\n      ### These models are single-speaker and use the International Phonetic Alphabet (IPA) for inference and training.\r\n      if [[ ${lang_code} != "de-DE" ]]; then\r\n        models_tts+=(\r\n            "${riva_ngc_org}/${riva_ngc_team}/models_tts_fastpitch_hifigan_${modified_lang_code}_f_ipa:${riva_ngc_model_version}-${riva_target_gpu_family}-${riva_tegra_platform}"\r\n        )\r\n      fi\r\n      models_tts+=(\r\n          "${riva_ngc_org}/${riva_ngc_team}/models_tts_fastpitch_hifigan_${modified_lang_code}_m_ipa:${riva_ngc_model_version}-${riva_target_gpu_family}-${riva_tegra_platform}"\r\n      )\r\n    fi\r\n  else\r\n    if [[ ${lang_code} == "en-US" ]]; then\r\n      models_tts+=(\r\n      ### These models have been trained with energy conditioning and use the International Phonetic Alphabet (IPA) for inference and training.\r\n          "${riva_ngc_org}/${riva_ngc_team}/rmir_tts_fastpitch_hifigan_en_us_ipa:${riva_ngc_model_version}"\r\n      #    "${riva_ngc_org}/${riva_ngc_team}/rmir_tts_radtts_hifigan_en_us_ipa:${riva_ngc_model_version}"\r\n\r\n      ### This model uses the ARPABET for inference and training.\r\n      #    "${riva_ngc_org}/${riva_ngc_team}/rmir_tts_fastpitch_hifigan_en_us:${riva_ngc_model_version}"\r\n      )\r\n    elif [[ ${lang_code} == "zh-CN" ]]; then\r\n      models_tts+=(\r\n      ### This model is multi-speaker with emotion and and use the International Phonetic Alphabet (IPA) for inference and training.\r\n          "${riva_ngc_org}/${riva_ngc_team}/rmir_tts_fastpitch_hifigan_zh_cn_ipa:${riva_ngc_model_version}"\r\n      )\r\n    else\r\n      ### These models are single-speaker and use the International Phonetic Alphabet (IPA) for inference and training.\r\n      if [[ ${lang_code} != "de-DE" ]]; then\r\n        models_tts+=(\r\n            "${riva_ngc_org}/${riva_ngc_team}/rmir_tts_fastpitch_hifigan_${modified_lang_code}_f_ipa:${riva_ngc_model_version}"\r\n        )\r\n      fi\r\n      models_tts+=(\r\n          "${riva_ngc_org}/${riva_ngc_team}/rmir_tts_fastpitch_hifigan_${modified_lang_code}_m_ipa:${riva_ngc_model_version}"\r\n      )\r\n    fi\r\n  fi\r\ndone\r\n\r\n######### NMT models ###############\r\n\r\n# Models follow Source language _ One or more target languages model architecture\r\n# Source or target language "any" means the model supports 32 languages mentioned in docs.\r\n# e.g., rmir_nmt_de_en_24x6 is a German to English 24x6 bilingual model\r\n# and rmir_megatronnmt_en_any_500m is a English to 32 languages megatron model\r\n\r\nmodels_nmt=(\r\n  ###### Bilingual models\r\n  #"${riva_ngc_org}/${riva_ngc_team}/rmir_nmt_en_de_24x6:${riva_ngc_model_version}"\r\n  #"${riva_ngc_org}/${riva_ngc_team}/rmir_nmt_en_es_24x6:${riva_ngc_model_version}"\r\n  #"${riva_ngc_org}/${riva_ngc_team}/rmir_nmt_en_zh_24x6:${riva_ngc_model_version}"\r\n  #"${riva_ngc_org}/${riva_ngc_team}/rmir_nmt_en_ru_24x6:${riva_ngc_model_version}"\r\n  #"${riva_ngc_org}/${riva_ngc_team}/rmir_nmt_en_fr_24x6:${riva_ngc_model_version}"\r\n  #"${riva_ngc_org}/${riva_ngc_team}/rmir_nmt_de_en_24x6:${riva_ngc_model_version}"\r\n  #"${riva_ngc_org}/${riva_ngc_team}/rmir_nmt_es_en_24x6:${riva_ngc_model_version}"\r\n  #"${riva_ngc_org}/${riva_ngc_team}/rmir_nmt_ru_en_24x6:${riva_ngc_model_version}"\r\n  #"${riva_ngc_org}/${riva_ngc_team}/rmir_nmt_zh_en_24x6:${riva_ngc_model_version}"\r\n  #"${riva_ngc_org}/${riva_ngc_team}/rmir_nmt_fr_en_24x6:${riva_ngc_model_version}"\r\n\r\n  ###### Multilingual models\r\n  #"${riva_ngc_org}/${riva_ngc_team}/rmir_nmt_en_deesfr_24x6:${riva_ngc_model_version}"\r\n  #"${riva_ngc_org}/${riva_ngc_team}/rmir_nmt_en_deesfr_12x2:${riva_ngc_model_version}"\r\n  #"${riva_ngc_org}/${riva_ngc_team}/rmir_nmt_deesfr_en_24x6:${riva_ngc_model_version}"\r\n  #"${riva_ngc_org}/${riva_ngc_team}/rmir_nmt_deesfr_en_12x2:${riva_ngc_model_version}"\r\n\r\n  ###### Megatron models\r\n  #"${riva_ngc_org}/${riva_ngc_team}/rmir_megatronnmt_any_en_500m:${riva_ngc_model_version}"\r\n  #"${riva_ngc_org}/${riva_ngc_team}/rmir_megatronnmt_en_any_500m:${riva_ngc_model_version}"\r\n)\r\n\r\nNGC_TARGET=${riva_ngc_org}\r\nif [[ ! -z ${riva_ngc_team} ]]; then\r\n  NGC_TARGET="${NGC_TARGET}/${riva_ngc_team}"\r\nelse\r\n  team="\\"\\""\r\nfi\r\n\r\n# Specify paths to SSL Key and Certificate files to use TLS/SSL Credentials for a secured connection.\r\n# If either are empty, an insecure connection will be used.\r\n# Stored within container at /ssl/servert.crt and /ssl/server.key\r\n# Optional, one can also specify a root certificate, stored within container at /ssl/root_server.crt\r\nssl_server_cert=""\r\nssl_server_key=""\r\nssl_root_cert=""\r\n\r\n# define Docker images required to run Riva\r\nimage_speech_api="nvcr.io/${NGC_TARGET}/riva-speech:${riva_ngc_image_version}"\r\n\r\n# define Docker images required to setup Riva\r\nimage_init_speech="nvcr.io/${NGC_TARGET}/riva-speech:${riva_ngc_image_version}-servicemaker"\r\n\r\n# daemon names\r\nriva_daemon_speech="riva-speech"\r\nif [[ $riva_target_gpu_family != "tegra" ]]; then\r\n    riva_daemon_client="riva-client"\r\nfi\n'})})]}),"\n",(0,i.jsxs)(n.p,{children:["Use a similar method to modify ",(0,i.jsx)(n.code,{children:"/etc/docker/daemon.json"}),"."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sh",children:'sudo vim /etc/docker/daemon.json\r\n# Add this line >> "default-runtime": "nvidia"\r\n\r\n# Press the `ESC` on the keyboard to exit edit mode, then use the shortcut `Shift+Z Z` to save the edited content and close the editor.\r\n\r\nsudo systemctl restart docker\n'})}),"\n",(0,i.jsx)(n.p,{children:"The configuration file after editing like this:"}),"\n",(0,i.jsxs)(r,{children:[(0,i.jsx)("summary",{children:" /etc/docker/daemon.json "}),(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-json",children:'{   \r\n    "default-runtime": "nvidia",\r\n        "runtimes": {\r\n        "nvidia": {\r\n            "path": "nvidia-container-runtime",\r\n            "runtimeArgs": []\r\n        }\r\n    }\r\n}\n'})})]}),"\n",(0,i.jsx)(n.p,{children:"Use the following command to initialize and start Riva:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sh",children:"sudo bash riva_init.sh\r\nsudo bash riva_start.sh\n"})}),"\n",(0,i.jsx)("div",{align:"center",children:(0,i.jsx)("img",{width:800,src:"https://files.seeedstudio.com/wiki/reComputer/Application/Local_Voice_Chatbot/setup_riva_4.png"})}),"\n",(0,i.jsx)(n.admonition,{type:"info",children:(0,i.jsx)(n.p,{children:"Please note, you need to keep this terminal alive."})}),"\n",(0,i.jsx)(n.h3,{id:"install-and-run-llm",children:"Install and run LLM"}),"\n",(0,i.jsxs)(n.p,{children:["To simplify the installation process, we can refer to Dusty's ",(0,i.jsx)(n.a,{href:"https://github.com/dusty-nv/jetson-containers/tree/master/packages/llm/text-generation-inference",children:"jetson-containers"})," project to install ",(0,i.jsx)(n.a,{href:"https://github.com/huggingface/text-generation-inference",children:"text generation inference"}),", and use text generation inference to load the ",(0,i.jsx)(n.a,{href:"https://huggingface.co/meta-llama/Llama-2-7b-chat-hf",children:"Llama2 7B"})," large language model. Open a new terminal and run the following command."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sh",children:"cd ~\r\ngit clone https://github.com/dusty-nv/jetson-containers.git\r\ncd jetson-containers\r\npip install -r requirements.txt\r\n./run.sh $(./autotag text-generation-inference)\r\nexport HUGGING_FACE_HUB_TOKEN=<your hugging face token>\r\ntext-generation-launcher --model-id meta-llama/Llama-2-7b-chat-hf --port 8899\n"})}),"\n",(0,i.jsx)(n.admonition,{type:"info",children:(0,i.jsxs)(n.p,{children:["You can obtain the hugging face token ",(0,i.jsx)(n.a,{href:"https://huggingface.co/docs/hub/security-tokens",children:"here"}),"."]})}),"\n",(0,i.jsx)("div",{align:"center",children:(0,i.jsx)("img",{width:800,src:"https://files.seeedstudio.com/wiki/reComputer/Application/Local_Voice_Chatbot/install_run_llm.png"})}),"\n",(0,i.jsx)(n.admonition,{type:"info",children:(0,i.jsx)(n.p,{children:"Please note, you need to keep this terminal alive."})}),"\n",(0,i.jsx)(n.h3,{id:"clone-local-chatbot-demo-and-try-to-run-it",children:"Clone local chatbot demo and try to run it."}),"\n",(0,i.jsx)(n.p,{children:"Now, you should have at least two terminals open, one running the Riva server and the other running the text generation inference server. Next, we need to open a new terminal to run our demo."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sh",children:"cd ~\r\ngit clone https://github.com/yuyoujiang/Deploy-Riva-LLama-on-Jetson.git\r\ncd Deploy-Riva-LLama-on-Jetson\r\n\r\n# Query audio input/output devices.\r\npython3 local_chatbot.py --list-input-devices\r\npython3 local_chatbot.py --list-output-devices\r\n\r\npython3 local_chatbot.py --input-device <your device id> --output-device <your device id>\r\n# For example: python3 local_chatbot.py --input-device 25 --output-device 30\n"})}),"\n",(0,i.jsx)(n.h2,{id:"effect-demonstration",children:"Effect Demonstration"}),"\n",(0,i.jsx)("div",{align:"center",children:(0,i.jsx)("iframe",{width:800,height:450,src:"https://www.youtube.com/embed/Nc3D-qITDoU?si=aWI7Z5IEprRKfuKE",title:"YouTube video player",frameBorder:0,allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",allowFullScreen:!0})}),"\n",(0,i.jsx)(n.h2,{id:"references",children:"References"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://wiki.seeedstudio.com/Local_Voice_Chatbot/",children:"https://wiki.seeedstudio.com/"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://www.hackster.io/wxxniubi8/build-an-ai-chatbot-using-riva-and-openai-13dc41",children:"build-an-ai-chatbot-using-riva-and-openai"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://github.com/dusty-nv/jetson-containers/tree/cb6c847f88df221e705397a1ee98424c2e893243/packages/llm/text-generation-inference",children:"https://github.com/dusty-nv/jetson-containers"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://github.com/huggingface/text-generation-inference",children:"https://github.com/huggingface/text-generation-inference"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://huggingface.co/meta-llama",children:"https://huggingface.co/meta-llama"})}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>o,x:()=>s});var i=r(6540);const t={},a=i.createContext(t);function o(e){const n=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);